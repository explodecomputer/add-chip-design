---
title: Strategies for chip design to aid with accurate imputation across multiple sub populations
author: Gibran Hemani and Dan Lawson
---

The challenge - describe chip and target population. Current issues etc

Two options:

1. Variant selection for post-imputation checking of reliable performance

For example, if we genotype variants that we want to perform well as an indicator of the parity of accuracy across different ethnic groups. 

Suggestion 1: Include a set of ancestry informative markers on the SNP chip and then exclude them when performing imputation, in order to evaluate how well they are imputed against the known genotype value. These tend to be variants that have high Fst in global population samples. We could ask whether variants that differentiate a pair of populations have been as well imputed as variants that differentiate other pairs of populations. 

Potential problems: are variants with high Fst special and therefore not representative of the rest of the variants? e.g. are they related to a sweep or hotspot

Suggestion 2: Maf - Info relationship for each sub population. No need for specific variants to be included

Suggestion 3: Run simulations where sequence data is thinned to genotype data, and see which has a) highest precision and b) highest accuracy. Some kind of ROC curve.


2. Variant selection for maximisation of imputation accuracy

Illumina GSA insights from Dan
- Using a new selection system meant that there was less overlap of SNPs compared to other panels. Analysis (confidential) showed that the selected SNPs on other chips were poorly imputed by GSA SNPs. This might be a problem for meta-analysis. We could speak to Jonathan Marchini and Ben Neale about this.
- The selection method was 1. take all SNPs from 2M MEGA array and 2. Retain variants that were common in multiple ethnicities. This seems to have led to the problem above, and also didn't really lead to good performance of the other ethnicities.
- GSA backbone was not built with a priority to allow meta analysis of multiple cohorts on different chips, though it should have been a consideration if it was to be used in a scientific and not consumer context

What we could do:

Use HGDP and SGDP (diverse sequence panels that are not included on HRC) as our target datasets

1. Choose a set of SNPs
2. Create dataset on HGDP+SGDP
3. Impute with HRC
4. Compare imputation of different ethnicities against sequence data

Variations:
- Different SNP sets
- Imputing different major populations separately
- Ways to evaluate performance


One way to create a SNP set:

1. Get recombination map for each major population. 
2. For each recombination interval find a set of SNPs that tag all the haplotypes for that population
    - e.g. use LD scores. Take the one with the highest LD score, then factor out that variant and take the next highest LD score and so on
    - e.g. use PCA. Take PCA of the region, find how many PCs needed to explain e.g. 80% of the variance, and keep the variant with the top loading for each PC






- Question: how well has the UKBB chip performed on different ethnicities?
    + Calculate info scores on subsets of the samples
- Question: what is the guidance for phasing of diverse populations e.g. with EAGLE v3
- Question: Million vets program must have had to tackle this issue - what did they do?

HGDP - https://www.biorxiv.org/content/10.1101/674986v1.full.pdf
SGDP - https://reichdata.hms.harvard.edu/pub/datasets/sgdp/

